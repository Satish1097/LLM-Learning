{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "Summary with OPENAI API Frontier LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! I'm glad you've reached out. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_prompt_for(\u001b[43med\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ed' is not defined"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise Day1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Implementing a neural network using PyTorch involves a few key steps. Here’s a step-by-step guide on how you can do this:\n",
      "\n",
      "### Step 1: Set Up Your Environment\n",
      "First, make sure you have PyTorch installed. You can install it using pip:\n",
      "\n",
      "```bash\n",
      "pip install torch torchvision\n",
      "```\n",
      "\n",
      "### Step 2: Import Required Libraries\n",
      "You need to import `torch` and other relevant libraries:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "import torchvision.transforms as transforms\n",
      "from torch.utils.data import DataLoader\n",
      "```\n",
      "\n",
      "### Step 3: Prepare the Dataset\n",
      "You can use existing datasets from `torchvision.datasets` or load your own data. Here's an example using the MNIST dataset:\n",
      "\n",
      "```python\n",
      "from torchvision import datasets\n",
      "\n",
      "# Define transformations (normalization, etc.)\n",
      "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
      "\n",
      "# Load the dataset\n",
      "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
      "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
      "```\n",
      "\n",
      "### Step 4: Define the Neural Network Architecture\n",
      "Create a subclass of `nn.Module` to define your neural network:\n",
      "\n",
      "```python\n",
      "class SimpleNN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(SimpleNN, self).__init__()\n",
      "        self.fc1 = nn.Linear(28*28, 128)  # Input layer to hidden layer\n",
      "        self.fc2 = nn.Linear(128, 64)      # Hidden layer\n",
      "        self.fc3 = nn.Linear(64, 10)       # Hidden layer to output layer\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = x.view(-1, 28*28)  # Flatten the image\n",
      "        x = torch.relu(self.fc1(x))  # Activation function\n",
      "        x = torch.relu(self.fc2(x))\n",
      "        x = self.fc3(x)\n",
      "        return x\n",
      "```\n",
      "\n",
      "### Step 5: Initialize the Model, Loss Function, and Optimizer\n",
      "Create an instance of the model, define a loss function, and choose an optimizer:\n",
      "\n",
      "```python\n",
      "model = SimpleNN()\n",
      "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
      "```\n",
      "\n",
      "### Step 6: Train the Model\n",
      "Run a training loop over the dataset:\n",
      "\n",
      "```python\n",
      "num_epochs = 5\n",
      "\n",
      "for epoch in range(num_epochs):\n",
      "    for images, labels in train_loader:\n",
      "        optimizer.zero_grad()  # Clear gradients\n",
      "        outputs = model(images)  # Forward pass\n",
      "        loss = criterion(outputs, labels)  # Calculate loss\n",
      "        loss.backward()  # Backward pass\n",
      "        optimizer.step()  # Update weights\n",
      "\n",
      "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
      "```\n",
      "\n",
      "### Step 7: Evaluate the Model (Optional)\n",
      "After training, you can evaluate your model using test data:\n",
      "\n",
      "```python\n",
      "# Load test dataset \n",
      "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
      "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
      "\n",
      "model.eval()  # Set the model to evaluation mode\n",
      "correct = 0\n",
      "total = 0\n",
      "\n",
      "with torch.no_grad():  # No need to track gradients during testing\n",
      "    for images, labels in test_loader:\n",
      "        outputs = model(images)\n",
      "        _, predicted = torch.max(outputs.data, 1)\n",
      "        total += labels.size(0)\n",
      "        correct += (predicted == labels).sum().item()\n",
      "\n",
      "print(f'Accuracy: {100 * correct / total:.2f}%')\n",
      "```\n",
      "\n",
      "### Conclusion\n",
      "You’ve built a simple neural network using PyTorch! This guide walked you through the process of setting it up, defining the architecture, training the model, and evaluating it. From here, you can explore more complex networks, datasets, and techniques like convolutional layers for image processing tasks, recurrent layers for sequential data, etc.\n",
      "\n",
      "Feel free to ask if you have specific questions or further details you would like to know!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "MODEL_GPT='GPT-4o-mini'\n",
    "\n",
    "system_prompt = \"Neural Network\"\n",
    "user_prompt = \"\"\"\n",
    "Explain how can I use Pytorch to implemet Neural Network\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\",\"content\":system_prompt},\n",
    "    {\"role\":\"user\",\"content\":user_prompt}\n",
    "] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "\n",
    "# Step 4: print the result\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
